{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "307fb67c",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70b1f867",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import types\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import *\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "031d7ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/avelazquez/spark/spark-3.0.3-bin-hadoop3.2/jars/spark-unsafe_2.12-3.0.3.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "22/03/06 14:39:29 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('test') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63d515aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-03-05 17:32:45--  https://nyc-tlc.s3.amazonaws.com/trip+data/fhvhv_tripdata_2021-02.csv\n",
      "Resolving nyc-tlc.s3.amazonaws.com (nyc-tlc.s3.amazonaws.com)... 54.231.194.57\n",
      "Connecting to nyc-tlc.s3.amazonaws.com (nyc-tlc.s3.amazonaws.com)|54.231.194.57|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 733822658 (700M) [text/csv]\n",
      "Saving to: ‘fhvhv_tripdata_2021-02.csv’\n",
      "\n",
      "fhvhv_tripdata_2021 100%[===================>] 699.83M  63.2MB/s    in 9.6s    \n",
      "\n",
      "2022-03-05 17:32:55 (73.2 MB/s) - ‘fhvhv_tripdata_2021-02.csv’ saved [733822658/733822658]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://nyc-tlc.s3.amazonaws.com/trip+data/fhvhv_tripdata_2021-02.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1519ef5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!head fhvhv_tripdata_2021-02.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ffe4e40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/avelazquez/data-engineering-zoomcamp/week_5_batch_processing/code'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f4c72358",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = types.StructType([\n",
    "    types.StructField('hvfhs_license_num', types.StringType(), True),\n",
    "    types.StructField('dispatching_base_num', types.StringType(), True),\n",
    "    types.StructField('pickup_datetime', types.TimestampType(), True),\n",
    "    types.StructField('dropoff_datetime', types.TimestampType(), True),\n",
    "    types.StructField('PULocationID', types.IntegerType(), True),\n",
    "    types.StructField('DOLocationID', types.IntegerType(), True),\n",
    "    types.StructField('SR_Flag', types.StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d22bc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .schema(schema) \\\n",
    "    .csv('fhvhv_tripdata_2021-02.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bacde226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- hvfhs_license_num: string (nullable = true)\n",
      " |-- dispatching_base_num: string (nullable = true)\n",
      " |-- pickup_datetime: timestamp (nullable = true)\n",
      " |-- dropoff_datetime: timestamp (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- SR_Flag: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "16768c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.repartition(24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0398d89f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.write.parquet('fhvhv/2021/02/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a70ca43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet('fhvhv/2021/02/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "deaf6c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------------+-------------------+-------------------+------------+------------+-------+\n",
      "|hvfhs_license_num|dispatching_base_num|    pickup_datetime|   dropoff_datetime|PULocationID|DOLocationID|SR_Flag|\n",
      "+-----------------+--------------------+-------------------+-------------------+------------+------------+-------+\n",
      "|           HV0003|              B02887|2021-02-06 01:18:35|2021-02-06 01:40:34|         163|         235|   null|\n",
      "|           HV0005|              B02510|2021-02-05 07:13:06|2021-02-05 07:31:56|         225|         181|   null|\n",
      "|           HV0003|              B02869|2021-02-04 16:56:52|2021-02-04 17:21:36|         260|          95|   null|\n",
      "|           HV0003|              B02871|2021-02-03 18:34:17|2021-02-03 18:57:12|         235|          60|   null|\n",
      "|           HV0003|              B02869|2021-02-04 07:25:09|2021-02-04 07:30:34|          55|          55|   null|\n",
      "|           HV0003|              B02836|2021-02-04 23:15:27|2021-02-04 23:34:29|          74|          81|   null|\n",
      "|           HV0003|              B02882|2021-02-05 07:45:49|2021-02-05 08:05:03|         239|         231|   null|\n",
      "|           HV0003|              B02887|2021-02-03 17:33:59|2021-02-03 17:47:14|          95|         196|   null|\n",
      "|           HV0003|              B02877|2021-02-03 09:33:06|2021-02-03 09:45:59|         241|         265|   null|\n",
      "|           HV0003|              B02872|2021-02-02 12:58:46|2021-02-02 13:06:20|          90|         137|   null|\n",
      "|           HV0003|              B02764|2021-02-05 22:25:20|2021-02-05 22:28:27|           7|           7|   null|\n",
      "|           HV0003|              B02882|2021-02-04 19:57:44|2021-02-04 20:05:24|         231|         246|   null|\n",
      "|           HV0003|              B02764|2021-02-02 08:43:57|2021-02-02 08:53:46|         108|          29|   null|\n",
      "|           HV0003|              B02866|2021-02-04 05:51:50|2021-02-04 06:21:25|          11|         112|   null|\n",
      "|           HV0003|              B02882|2021-02-05 16:13:02|2021-02-05 16:27:48|         229|         234|   null|\n",
      "|           HV0005|              B02510|2021-02-04 17:15:28|2021-02-04 17:24:46|          10|         218|   null|\n",
      "|           HV0003|              B02617|2021-02-04 09:59:58|2021-02-04 10:29:13|          49|         232|   null|\n",
      "|           HV0005|              B02510|2021-02-05 23:34:27|2021-02-05 23:51:05|         125|          17|   null|\n",
      "|           HV0003|              B02875|2021-02-05 20:52:58|2021-02-05 21:19:59|          47|          68|   null|\n",
      "|           HV0003|              B02875|2021-02-04 18:11:00|2021-02-04 18:37:24|          41|         223|   null|\n",
      "+-----------------+--------------------+-------------------+-------------------+------------+------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4941cc4",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "336616e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_directory_size(directory):\n",
    "    \"\"\"Returns the `directory` size in bytes.\"\"\"\n",
    "    total = 0\n",
    "    try:\n",
    "        # print(\"[+] Getting the size of\", directory)\n",
    "        for entry in os.scandir(directory):\n",
    "            if entry.is_file():\n",
    "                # if it's a file, use stat() function\n",
    "                total += entry.stat().st_size\n",
    "            elif entry.is_dir():\n",
    "                # if it's a directory, recursively call this function\n",
    "                total += get_directory_size(entry.path)\n",
    "    except NotADirectoryError:\n",
    "        # if `directory` isn't a directory, get the file size then\n",
    "        return os.path.getsize(directory)\n",
    "    except PermissionError:\n",
    "        # if for whatever reason we can't open the folder, return 0\n",
    "        return 0\n",
    "    return total\n",
    "\n",
    "def get_size_format(b, factor=1024, suffix=\"B\"):\n",
    "    \"\"\"\n",
    "    Scale bytes to its proper byte format\n",
    "    e.g:\n",
    "        1253656 => '1.20MB'\n",
    "        1253656678 => '1.17GB'\n",
    "    \"\"\"\n",
    "    for unit in [\"\", \"K\", \"M\", \"G\", \"T\", \"P\", \"E\", \"Z\"]:\n",
    "        if b < factor:\n",
    "            return f\"{b:.2f}{unit}{suffix}\"\n",
    "        b /= factor\n",
    "    return f\"{b:.2f}Y{suffix}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5f16232f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209.52MB\n"
     ]
    }
   ],
   "source": [
    "directory = './fhvhv/2021/02'\n",
    "print(get_size_format(get_directory_size(directory)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33783b84",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8efe7aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "367170"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df \\\n",
    "    .withColumn('pickup_date',F.to_date('pickup_datetime')) \\\n",
    "    .filter(F.to_date('pickup_datetime') == '2021-02-15') \\\n",
    "    .count() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a32b0c9",
   "metadata": {},
   "source": [
    "## Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "05ba4f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------------+-------------------+-------------------+------------+------------+-------+\n",
      "|hvfhs_license_num|dispatching_base_num|    pickup_datetime|   dropoff_datetime|PULocationID|DOLocationID|SR_Flag|\n",
      "+-----------------+--------------------+-------------------+-------------------+------------+------------+-------+\n",
      "|           HV0003|              B02887|2021-02-06 01:18:35|2021-02-06 01:40:34|         163|         235|   null|\n",
      "|           HV0005|              B02510|2021-02-05 07:13:06|2021-02-05 07:31:56|         225|         181|   null|\n",
      "|           HV0003|              B02869|2021-02-04 16:56:52|2021-02-04 17:21:36|         260|          95|   null|\n",
      "|           HV0003|              B02871|2021-02-03 18:34:17|2021-02-03 18:57:12|         235|          60|   null|\n",
      "|           HV0003|              B02869|2021-02-04 07:25:09|2021-02-04 07:30:34|          55|          55|   null|\n",
      "|           HV0003|              B02836|2021-02-04 23:15:27|2021-02-04 23:34:29|          74|          81|   null|\n",
      "|           HV0003|              B02882|2021-02-05 07:45:49|2021-02-05 08:05:03|         239|         231|   null|\n",
      "|           HV0003|              B02887|2021-02-03 17:33:59|2021-02-03 17:47:14|          95|         196|   null|\n",
      "|           HV0003|              B02877|2021-02-03 09:33:06|2021-02-03 09:45:59|         241|         265|   null|\n",
      "|           HV0003|              B02872|2021-02-02 12:58:46|2021-02-02 13:06:20|          90|         137|   null|\n",
      "|           HV0003|              B02764|2021-02-05 22:25:20|2021-02-05 22:28:27|           7|           7|   null|\n",
      "|           HV0003|              B02882|2021-02-04 19:57:44|2021-02-04 20:05:24|         231|         246|   null|\n",
      "|           HV0003|              B02764|2021-02-02 08:43:57|2021-02-02 08:53:46|         108|          29|   null|\n",
      "|           HV0003|              B02866|2021-02-04 05:51:50|2021-02-04 06:21:25|          11|         112|   null|\n",
      "|           HV0003|              B02882|2021-02-05 16:13:02|2021-02-05 16:27:48|         229|         234|   null|\n",
      "|           HV0005|              B02510|2021-02-04 17:15:28|2021-02-04 17:24:46|          10|         218|   null|\n",
      "|           HV0003|              B02617|2021-02-04 09:59:58|2021-02-04 10:29:13|          49|         232|   null|\n",
      "|           HV0005|              B02510|2021-02-05 23:34:27|2021-02-05 23:51:05|         125|          17|   null|\n",
      "|           HV0003|              B02875|2021-02-05 20:52:58|2021-02-05 21:19:59|          47|          68|   null|\n",
      "|           HV0003|              B02875|2021-02-04 18:11:00|2021-02-04 18:37:24|          41|         223|   null|\n",
      "+-----------------+--------------------+-------------------+-------------------+------------+------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "36cf3cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 19:>                                                         (0 + 4) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------------+-------------------+-------------------+------------+------------+-------+-----------+-------------------+\n",
      "|hvfhs_license_num|dispatching_base_num|pickup_datetime    |dropoff_datetime   |PULocationID|DOLocationID|SR_Flag|pickup_date|TripDurationSeconds|\n",
      "+-----------------+--------------------+-------------------+-------------------+------------+------------+-------+-----------+-------------------+\n",
      "|HV0005           |B02510              |2021-02-11 13:40:44|2021-02-12 10:39:44|247         |41          |null   |2021-02-11 |-75540             |\n",
      "+-----------------+--------------------+-------------------+-------------------+------------+------------+-------+-----------+-------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df \\\n",
    "    .withColumn('pickup_date',F.to_date('pickup_datetime')) \\\n",
    "    .withColumn('TripDurationSeconds', col('pickup_datetime').cast('long') - col('dropoff_datetime').cast('long')) \\\n",
    "    .orderBy('TripDurationSeconds') \\\n",
    "    .show(1,truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0d6063",
   "metadata": {},
   "source": [
    "## Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bcefe587",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 35:=================================================>    (185 + 4) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+\n",
      "|dispatching_base_num|  count|\n",
      "+--------------------+-------+\n",
      "|              B02510|3233664|\n",
      "|              B02764| 965568|\n",
      "|              B02872| 882689|\n",
      "|              B02875| 685390|\n",
      "|              B02765| 559768|\n",
      "|              B02869| 429720|\n",
      "|              B02887| 322331|\n",
      "|              B02871| 312364|\n",
      "|              B02864| 311603|\n",
      "|              B02866| 311089|\n",
      "|              B02878| 305185|\n",
      "|              B02682| 303255|\n",
      "|              B02617| 274510|\n",
      "|              B02883| 251617|\n",
      "|              B02884| 244963|\n",
      "|              B02882| 232173|\n",
      "|              B02876| 215693|\n",
      "|              B02879| 210137|\n",
      "|              B02867| 200530|\n",
      "|              B02877| 198938|\n",
      "+--------------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df \\\n",
    "    .groupBy('dispatching_base_num') \\\n",
    "    .count() \\\n",
    "    .orderBy('count', ascending=False) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810b5ead",
   "metadata": {},
   "source": [
    "## Question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9691039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-03-06 14:36:48--  https://s3.amazonaws.com/nyc-tlc/misc/taxi+_zone_lookup.csv\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.229.112\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.229.112|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 12322 (12K) [application/octet-stream]\n",
      "Saving to: ‘taxi+_zone_lookup.csv’\n",
      "\n",
      "taxi+_zone_lookup.c 100%[===================>]  12.03K  --.-KB/s    in 0s      \n",
      "\n",
      "2022-03-06 14:36:49 (169 MB/s) - ‘taxi+_zone_lookup.csv’ saved [12322/12322]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://s3.amazonaws.com/nyc-tlc/misc/taxi+_zone_lookup.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0aa0e56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_zone = types.StructType([ \n",
    "        types.StructField('LocationID',types.IntegerType(),True), \n",
    "        types.StructField('Borough',types.StringType(),True), \n",
    "        types.StructField('Zone',types.StringType(),True), \n",
    "        types.StructField('service_zone',types.StringType(),True) \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a2e57f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zone = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .schema(schema_zone) \\\n",
    "    .csv('taxi+_zone_lookup.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e557064c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(LocationID,IntegerType,true),StructField(Borough,StringType,true),StructField(Zone,StringType,true),StructField(service_zone,StringType,true)))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_zone.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "564a5c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------------------+------------+\n",
      "|LocationID|      Borough|                Zone|service_zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "|         1|          EWR|      Newark Airport|         EWR|\n",
      "|         2|       Queens|         Jamaica Bay|   Boro Zone|\n",
      "|         3|        Bronx|Allerton/Pelham G...|   Boro Zone|\n",
      "|         4|    Manhattan|       Alphabet City| Yellow Zone|\n",
      "|         5|Staten Island|       Arden Heights|   Boro Zone|\n",
      "|         6|Staten Island|Arrochar/Fort Wad...|   Boro Zone|\n",
      "|         7|       Queens|             Astoria|   Boro Zone|\n",
      "|         8|       Queens|        Astoria Park|   Boro Zone|\n",
      "|         9|       Queens|          Auburndale|   Boro Zone|\n",
      "|        10|       Queens|        Baisley Park|   Boro Zone|\n",
      "|        11|     Brooklyn|          Bath Beach|   Boro Zone|\n",
      "|        12|    Manhattan|        Battery Park| Yellow Zone|\n",
      "|        13|    Manhattan|   Battery Park City| Yellow Zone|\n",
      "|        14|     Brooklyn|           Bay Ridge|   Boro Zone|\n",
      "|        15|       Queens|Bay Terrace/Fort ...|   Boro Zone|\n",
      "|        16|       Queens|             Bayside|   Boro Zone|\n",
      "|        17|     Brooklyn|             Bedford|   Boro Zone|\n",
      "|        18|        Bronx|        Bedford Park|   Boro Zone|\n",
      "|        19|       Queens|           Bellerose|   Boro Zone|\n",
      "|        20|        Bronx|             Belmont|   Boro Zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_zone.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "993d506d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_zone.write.parquet('zones')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2cdce65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zone = spark.read.parquet('zones')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a60a897c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------------------+------------+\n",
      "|LocationID|      Borough|                Zone|service_zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "|         1|          EWR|      Newark Airport|         EWR|\n",
      "|         2|       Queens|         Jamaica Bay|   Boro Zone|\n",
      "|         3|        Bronx|Allerton/Pelham G...|   Boro Zone|\n",
      "|         4|    Manhattan|       Alphabet City| Yellow Zone|\n",
      "|         5|Staten Island|       Arden Heights|   Boro Zone|\n",
      "|         6|Staten Island|Arrochar/Fort Wad...|   Boro Zone|\n",
      "|         7|       Queens|             Astoria|   Boro Zone|\n",
      "|         8|       Queens|        Astoria Park|   Boro Zone|\n",
      "|         9|       Queens|          Auburndale|   Boro Zone|\n",
      "|        10|       Queens|        Baisley Park|   Boro Zone|\n",
      "|        11|     Brooklyn|          Bath Beach|   Boro Zone|\n",
      "|        12|    Manhattan|        Battery Park| Yellow Zone|\n",
      "|        13|    Manhattan|   Battery Park City| Yellow Zone|\n",
      "|        14|     Brooklyn|           Bay Ridge|   Boro Zone|\n",
      "|        15|       Queens|Bay Terrace/Fort ...|   Boro Zone|\n",
      "|        16|       Queens|             Bayside|   Boro Zone|\n",
      "|        17|     Brooklyn|             Bedford|   Boro Zone|\n",
      "|        18|        Bronx|        Bedford Park|   Boro Zone|\n",
      "|        19|       Queens|           Bellerose|   Boro Zone|\n",
      "|        20|        Bronx|             Belmont|   Boro Zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_zone.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ea10640d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.registerTempTable('taxi')\n",
    "df_zone.registerTempTable('zone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1869adb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 36:==============>                                           (1 + 3) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------+----------------+\n",
      "|trips|   start_zone|destination_zone|\n",
      "+-----+-------------+----------------+\n",
      "|45041|East New York|   East New York|\n",
      "+-----+-------------+----------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_green_revenue = spark.sql(\"\"\"\n",
    "SELECT   COUNT(1) as trips\n",
    "        ,z.Zone as start_zone\n",
    "        ,z2.Zone as destination_zone\n",
    "FROM\n",
    "    taxi t \n",
    "    left join zone z \n",
    "        on t.PULocationID = z.LocationID\n",
    "    left join zone z2 \n",
    "        on t.DOLocationID = z2.LocationID\n",
    "GROUP BY \n",
    "         z.Zone\n",
    "        ,z2.Zone\n",
    "ORDER BY 1 DESC\n",
    "\"\"\").show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c415493",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
